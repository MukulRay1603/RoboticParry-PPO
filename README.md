# ğŸ¥· Samurai-Reflex-RL

### Reinforcement Learning for Robotic Sword Parrying in PyBullet



Samurai-Reflex-RL is a robotics project exploring  **defensive reflex learning ** using reinforcement learning (PPO) inside a custom PyBullet simulation.  

A 7-DOF robotic arm learns to  **detect, react and parry ** incoming sword attacks from an opponent robot using continuous control.



This repository contains the full environment, training code, evaluation pipeline and reproducible setup scripts.



---



 ## âœ¨ Features


- ğŸ—¡ï¸  **Scripted opponent attack model ** with curved BÃ©zier sword arcs  

- ğŸ›¡ï¸  **PPO-trained defensive policy **  that learns parry reflexes  

- ğŸ”  **Cooldown-based parry detection metric ** (fixes false positives)  

- ğŸ“Š Automatic  **evaluation graphs **: rewards, parries, distributions  

- ğŸ§ª  **Deterministic evaluation ** over 50 episodes  

- âš™ï¸ Fully reproducible  **UV-powered Python 3.10 environment **  

- ğŸª¶ Stable-Baselines3 + PyBullet + Gymnasium integration  


---



 # âš™ï¸ Installation  & Environment Setup (Windows + UV)



This project uses  **Python 3.10 ** because PyBullet wheels do not support 3.11+.  

We use   **UV  ** for a clean and stable virtual environment.



 ### 1ï¸âƒ£ Install UV



```bash
pip install uv
```





 ### 2ï¸âƒ£ Create environment (Python 3.10 required)

```bash
uv venv samurai _rl --python 3.10
```



If you have a global path for python version above 3.10, (ie. 3.11 and above use) after installing 3.10.



```bash
py -3.11 -m uv venv samurai _rl --python 3.10
```



 ### 3ï¸âƒ£ Activate environment



```bash
.  samurai _rl  Scripts  Activate.ps1
```



 ### 4ï¸âƒ£ Install dependencies



```bash

pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121

pip install "gymnasium [all]==1.2.2"

pip install "stable-baselines3 [extra]==2.2.1"

pip install https://github.com/bulletphysics/bullet3/releases/download/3.25/pybullet-3.25-cp310-cp310-win _amd64.whl

pip install matplotlib numpy

```



---



 # ğŸ§  Technical Overview



 ##ğŸ—¡ï¸ Opponent Attack Model



 *Attacks are not random â€” they follow a realistic sword swing using: *



* Quadratic BÃ©zier curve interpolation
* Wind-up â†’ Strike â†’ Follow-through phases
* Random lateral offsets for realism
* Continuous updates per simulation step
* This produces lifelike attack trajectories that the agent must defend against.



---



 # ğŸ” Cooldown-Based Parry Detection



Originally the system counted every contact frame as a â€œparryâ€, inflating numbers.



 *fixed this using: *



* Sliding cooldown window (â‰¥ 15 steps)
* Spatial position check
* Blade orientation check
* Contact force validation



Such as:



Mean parries per episode: 3.02

Total parries: 151

Total hits: 0

Parry rate: 100%





---



 # ğŸ¥‹ Training the Agent



```bash

python train.py

```



This will:



* CLI Training mode
* Train for N timesteps
* Save model to: models/samurai _ppo.zip



---



 # ğŸ”¬ Evaluation



 *Use event-based parry metric: *



```bash

python evaluate.py

```


 *NOTE:  *

* Running this without training works as a dry run
* It uses base reward system idea
* Running after training will show trained results



Output summary:



Mean reward: 8.66

Mean episode length: 200

Mean parries/episode: 3.02

Parry rate: 100%

Total hits: 0



---



 # ğŸš§ Known Limitations



* Opponent is scripted (not a learning agent)
* No real sensor noise or actuation latency
* Parry angle thresholds still coarse
* No domain randomization yet
* Designed for Windows; Linux requires PyBullet wheel rebuild



---
